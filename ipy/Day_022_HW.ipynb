{"cells":[{"source":["# ms-python.python added\n","import os\n","try:\n","\tos.chdir(os.path.join(os.getcwd(), 'ipy'))\n","\tprint(os.getcwd())\n","except:\n","\tpass"],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0},{"cell_type":"markdown","source":[" # 作業 : (Kaggle)鐵達尼生存預測\n"," https://www.kaggle.com/c/titanic"],"metadata":{}},{"cell_type":"markdown","source":[" # [作業目標]\n"," - 試著模仿範例寫法, 在鐵達尼生存預測中, 觀察標籤編碼與獨編碼熱的影響"],"metadata":{}},{"cell_type":"markdown","source":[" # [作業重點]\n"," - 回答在範例中的觀察結果\n"," - 觀察標籤編碼與獨熱編碼, 在特徵數量 / 邏輯斯迴歸分數 / 邏輯斯迴歸時間上, 分別有什麼影響 (In[3], Out[3], In[4], Out[4])"],"metadata":{}},{"cell_type":"markdown","source":[" # 作業1\n"," * 觀察範例，在房價預測中調整標籤編碼(Label Encoder) / 獨熱編碼 (One Hot Encoder) 方式，\n"," 對於線性迴歸以及梯度提升樹兩種模型，何者影響比較大?\n"," 線性回歸影響比較大 看得出來分處的差距頗大的"],"metadata":{}},{"source":["# 做完特徵工程前的所有準備 (與前範例相同)\n","import pandas as pd\n","import numpy as np\n","import copy, time\n","from sklearn.preprocessing import MinMaxScaler\n","from sklearn.model_selection import cross_val_score\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.preprocessing import LabelEncoder\n","\n","data_path = 'data/'\n","df_train = pd.read_csv(data_path + 'titanic_train.csv')\n","df_test = pd.read_csv(data_path + 'titanic_test.csv')\n","\n","train_Y = df_train['Survived']\n","ids = df_test['PassengerId']\n","df_train = df_train.drop(['PassengerId', 'Survived'] , axis=1)\n","df_test = df_test.drop(['PassengerId'] , axis=1)\n","df = pd.concat([df_train,df_test])\n","df.head()\n","\n",""],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0},{"source":["#只取類別值 (object) 型欄位, 存於 object_features 中\n","object_features = []\n","for dtype, feature in zip(df.dtypes, df.columns):\n","    if dtype == 'object':\n","        object_features.append(feature)\n","print(f'{len(object_features)} Numeric Features : {object_features}\\n')\n","\n","# 只留類別型欄位\n","df = df[object_features]\n","df = df.fillna('None')\n","train_num = train_Y.shape[0]\n","df.head()\n",""],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0},{"cell_type":"markdown","source":[" # 作業2\n"," * 鐵達尼號例題中，標籤編碼 / 獨熱編碼又分別對預測結果有何影響? (Hint : 參考今日範例)\n","  羅吉斯回歸是用來分類的 因此使用 OneHotEncoder 會比較明顯"],"metadata":{}},{"source":["# 標籤編碼 + 羅吉斯迴歸\n","df_temp = pd.DataFrame()\n","for e in object_features:\n","    df_temp[e] = LabelEncoder().fit_transform(df[e])\n","\n","train_X = df_temp[:train_num]\n","estimator = LogisticRegression()\n","start = time.time()\n","print(f'shape : {train_X.shape}')\n","print(f'score : {cross_val_score(estimator, train_X, train_Y, cv=5).mean()}')\n","print(f'time : {time.time() - start} sec')\n","\n","\n",""],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0},{"source":["# 獨熱編碼 + 羅吉斯迴歸\n","df_temp = pd.get_dummies(df)\n","train_X = df_temp[:train_num]\n","estimator = LogisticRegression()\n","start = time.time()\n","print(f'shape : {train_X.shape}')\n","print(f'score : {cross_val_score(estimator, train_X, train_Y, cv=5).mean()}')\n","print(f'time : {time.time() - start} sec')\n","\n","\n",""],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0},{"source":["\n","\n","\n",""],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0}],"nbformat":4,"nbformat_minor":2,"metadata":{"language_info":{"name":"python","codemirror_mode":{"name":"ipython","version":3}},"orig_nbformat":2,"file_extension":".py","mimetype":"text/x-python","name":"python","npconvert_exporter":"python","pygments_lexer":"ipython3","version":3}}