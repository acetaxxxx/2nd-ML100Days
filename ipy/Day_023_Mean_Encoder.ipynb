{"cells":[{"source":["# ms-python.python added\n","import os\n","try:\n","\tos.chdir(os.path.join(os.getcwd(), 'ipy'))\n","\tprint(os.getcwd())\n","except:\n","\tpass"],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0},{"cell_type":"markdown","source":[" # 作業 : (Kaggle)鐵達尼生存預測\n"," https://www.kaggle.com/c/titanic"],"metadata":{}},{"cell_type":"markdown","source":[" # [作業目標]\n"," - 試著模仿範例寫法, 在鐵達尼生存預測中, 觀察均值編碼的效果"],"metadata":{}},{"cell_type":"markdown","source":[" # [作業重點]\n"," - 仿造範例, 完成標籤編碼與均值編碼搭配邏輯斯迴歸的預測\n"," - 觀察標籤編碼與均值編碼在特徵數量 / 邏輯斯迴歸分數 / 邏輯斯迴歸時間上, 分別有什麼影響 (In[3], Out[3], In[4], Out[4])"],"metadata":{}},{"cell_type":"markdown","source":[" # 作業1\n"," * 請仿照範例，將鐵達尼範例中的類別型特徵改用均值編碼實作一次"],"metadata":{}},{"source":["# 做完特徵工程前的所有準備 (與前範例相同)\n","import pandas as pd\n","import numpy as np\n","import copy, time\n","from sklearn.preprocessing import MinMaxScaler\n","from sklearn.model_selection import cross_val_score\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.preprocessing import LabelEncoder\n","\n","data_path = 'data/'\n","df_train = pd.read_csv(data_path + 'titanic_train.csv')\n","df_test = pd.read_csv(data_path + 'titanic_test.csv')\n","\n","train_Y = df_train['Survived']\n","ids = df_test['PassengerId']\n","df_train = df_train.drop(['PassengerId', 'Survived'] , axis=1)\n","df_test = df_test.drop(['PassengerId'] , axis=1)\n","df = pd.concat([df_train,df_test])\n","df.head()\n","\n",""],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0},{"source":["#只取類別值 (object) 型欄位, 存於 object_features 中\n","object_features = []\n","for dtype, feature in zip(df.dtypes, df.columns):\n","    if dtype == 'object':\n","        object_features.append(feature)\n","print(f'{len(object_features)} Numeric Features : {object_features}\\n')\n","\n","# 只留類別型欄位\n","df = df[object_features]\n","df = df.fillna('None')\n","train_num = train_Y.shape[0]\n","df.head()\n",""],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0},{"cell_type":"markdown","source":[" # 作業2\n"," * 觀察鐵達尼生存預測中，均值編碼與標籤編碼兩者比較，哪一個效果比較好? 可能的原因是什麼?\n"," 均值編碼比較好 因為結果是只有存在1 0 兩種結果"],"metadata":{}},{"source":["# 對照組 : 標籤編碼 + 邏輯斯迴歸\n","df_temp = pd.DataFrame()\n","for e in df.columns:\n","    df_temp[e] = LabelEncoder().fit_transform(df[e])\n","\n","train_X = df_temp[:train_num]\n","estimator = LogisticRegression()\n","start = time.time()\n","print(f'shape : {train_X.shape}')\n","print(f'score : {cross_val_score(estimator, train_X, train_Y, cv=5).mean()}')\n","print(f'time : {time.time() - start} sec')\n",""],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0},{"source":["# 均值編碼 + 邏輯斯迴歸\n","data = pd.concat([df[:train_num], train_Y], axis=1)\n","for e in df.columns:\n","    data_mean = data.groupby([e])['Survived'].mean().reset_index()\n","    data_mean.columns = [e,f'{e}_mean']    \n","    data = data.merge(data_mean,on=e,how='left')\n","    data = data.drop([e],axis =1 )\n","\n","data = data.drop(['Survived'],axis =1 )\n","train_X = data\n","estimator = LogisticRegression()\n","start = time.time()\n","print(f'shape : {train_X.shape}')\n","print(f'score : {cross_val_score(estimator, train_X, train_Y, cv=5).mean()}')\n","print(f'time : {time.time() - start} sec')\n","\n",""],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0},{"source":[""],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0}],"nbformat":4,"nbformat_minor":2,"metadata":{"language_info":{"name":"python","codemirror_mode":{"name":"ipython","version":3}},"orig_nbformat":2,"file_extension":".py","mimetype":"text/x-python","name":"python","npconvert_exporter":"python","pygments_lexer":"ipython3","version":3}}